
---

## ⚙️ How to Run
1. Open the notebook in [Google Colab](https://colab.research.google.com/).
2. Upload your video file.
3. Run all cells — the model will:
   - Extract frames
   - Generate captions
   - Convert them to speech
4. Check the `output/` folder for results.

---

## 🎯 Applications
- Video accessibility tools for the visually impaired  
- Automated video summarization  
- Multimedia content tagging  
- Interactive AI assistants

---

## 📈 Future Improvements
- Add multi-language TTS  
- Integrate Whisper for speech recognition  
- Use faster captioning models (e.g. BLIP-2, LLaVA)

---

## 👤 Author
**Omar Gira**  
AI Engineer | Data Science Enthusiast  
📧 [Add your email or LinkedIn here]  
💻 [GitHub Profile](https://github.com/OmarGira)

---

⭐ *If you like this project, give it a star on GitHub!*
